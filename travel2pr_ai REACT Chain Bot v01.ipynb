{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment API Keys variables from .env file \n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt templates\n",
    "condense_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Given the conversation history and the latest user query, rephrase the question to be standalone, keeping it concise but maintaining all necessary details.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### Latest User Query:\n",
    "{question}\n",
    "\n",
    "### Standalone Question for Retrieval:\n",
    "\"\"\")\n",
    "\n",
    "combine_docs_custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are an AI travel planner helping users design an itinerary. Use the retrieved information about landmarks and the user's past preferences to generate a relevant and coherent travel recommendation.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User's Latest Question:\n",
    "{question}\n",
    "\n",
    "### Retrieved Landmark Information:\n",
    "{context}\n",
    "\n",
    "### Instructions:\n",
    "- Provide a well-structured travel recommendation based on the retrieved landmarks.\n",
    "- Ensure continuity with previous discussions.\n",
    "- Prioritize landmarks that match the user‚Äôs preferences.\n",
    "- If multiple options exist, suggest the best ones with reasoning.\n",
    "- Avoid repeating information already given in the conversation.\n",
    "- In the end ask the user which of these locations you will like to visit.\n",
    "\n",
    "### Final Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larry\\AppData\\Local\\Temp\\ipykernel_1932\\3204885827.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "#Initialize LLM with ReAct Chain\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "\n",
    "# Define memory to store conversation history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "\n",
    "# Function to print chat history\n",
    "def print_chat_history():\n",
    "    print(\"\\nChat History:\")\n",
    "    for idx, msg in enumerate(memory.chat_memory.messages):\n",
    "        role = \"User\" if msg.type == \"human\" else \"AI\"\n",
    "        print(f\"{role}: {msg.content}\")\n",
    "\n",
    "# Connect to your existing ChromaDB collection\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"landmarks_rag\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "#Define the retriever and chain\n",
    "retriever = vectorstore.as_retriever(k=3)  # This fetches relevant landmarks\n",
    "\n",
    "# Set up the conversational retrieval chain\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,  # Using OpenAI's ChatGPT as the LLM\n",
    "    retriever=retriever,  # Connect to your ChromaDB retriever\n",
    "    memory=memory,\n",
    "    condense_question_prompt=condense_prompt,  # Ensures refined queries for retrieval\n",
    "    combine_docs_chain_kwargs=dict(prompt=combine_docs_custom_prompt)  # Customizes how retrieved docs are used\n",
    ")\n",
    "\n",
    "# Wrap QA Chain as a Tool \n",
    "qa_tool = Tool( name=\"Puerto Rico Travel Guide\",\n",
    "               func=retrieval_chain.run,\n",
    "               description=\"Retrieve the best places to visit in Puerto Rico based on user queries.\" \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larry\\AppData\\Local\\Temp\\ipykernel_1932\\3024074906.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  location_extraction_chain = LLMChain( llm=llm,\n"
     ]
    }
   ],
   "source": [
    "# =======================# 2. Extracting Locations from QA Response# ======================= \n",
    "location_extraction_prompt = PromptTemplate( input_variables=[\"response\"], \n",
    "                                            template=\"\"\" Extract only the location names from the following text: \"{response}\" Provide the locations as a comma-separated list. \"\"\" \n",
    "                                            ) \n",
    "                                            \n",
    "location_extraction_chain = LLMChain( llm=llm,\n",
    "                                     prompt=location_extraction_prompt )\n",
    "\n",
    "def extract_locations_from_response(response):\n",
    "    \"\"\"Extracts locations using the LLM chain.\"\"\"\n",
    "    location_list = location_extraction_chain.run(response)\n",
    "    return [loc.strip() for loc in location_list.split(\",\") if loc.strip()] \n",
    "\n",
    "# =======================# 3. Asking the User for Their Selected Places# =======================\n",
    "def ask_user_for_places(query): \n",
    "    \"\"\"Asks the user to select places they are interested in visiting.\"\"\"\n",
    "    # Retrieve recommended locations from QA #\n",
    "    recommended_places = qa_tool.run(query) \n",
    "    extracted_locations = extract_locations_from_response(recommended_places)\n",
    "    if extracted_locations:\n",
    "        weather_details = get_weather_for_selected_places(extracted_locations)\n",
    "        res = f\"Here are some great places to visit: {', '.join(extracted_locations)}. {weather_details}. Which ones do you want to visit?\"\n",
    "        return res\n",
    "    else:\n",
    "        return \"I couldn't find relevant locations. Please try another query.\"\n",
    "    # Wrap as a Tool\n",
    "\n",
    "ask_places_tool = Tool( name=\"Ask User for Selected Places\", func=ask_user_for_places, description=\"Ask the user which places they want to visit from the recommended list.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================# 4. Getting Weather for Selected Locations# =======================# \n",
    "def get_weather(location):\n",
    "    \"\"\"Fetch real-time weather for a given location.\"\"\"\n",
    "    api_key = OPENWEATHER_API_KEY  # Replace with your API key\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": location, \"appid\": api_key, \"units\": \"metric\"}\n",
    "    response = requests.get(base_url, params=params) \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        weather = data[\"weather\"][0][\"description\"]\n",
    "        temp = data[\"main\"][\"temp\"]\n",
    "        return f\"The weather in {location} is {weather} with a temperature of {temp}¬∞C.\"\n",
    "    \n",
    "    else: return f\"Could not fetch weather data for {location}.\"\n",
    "    \n",
    "def get_weather_for_selected_places(selected_places):\n",
    "    \"\"\"Fetches weather for the user-selected locations.\"\"\"\n",
    "    locations = [loc.strip() for loc in selected_places.split(\",\") if loc.strip()]\n",
    "    if not locations:\n",
    "        return \"Please provide at least one valid location.\"\n",
    "    weather_reports = [get_weather(location) for location in locations]\n",
    "    return \"\\n\".join(weather_reports) \n",
    "\n",
    "# Wrap Weather Fetching as a Tool\n",
    "weather_tool = Tool( name=\"Get Weather for Selected Places\", func=get_weather_for_selected_places, description=\"Retrieve weather for the places selected by the user.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent( tools=[qa_tool, ask_places_tool, weather_tool],\n",
    "                          # Adding all tools \n",
    "                          llm=llm,\n",
    "                          agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, # Keeps conversation context\n",
    "                          verbose=True,\n",
    "                          memory=memory \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get recommended places\n",
    "response1 = agent.run(\"What are the best places to visit in Puerto Rico?\")\n",
    "\n",
    "print(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: \"Here are some great places: San Juan, El Yunque, Culebra... Which ones do you want to visit?\"# Simulate User Input \n",
    "user_selected_places = \"San Juan and Ponce\"\n",
    "\n",
    "# Step 2: Fetch weather for selected places \n",
    "response2 = agent.run(f\"I want to visit {user_selected_places}\")\n",
    "\n",
    "print(response2) # Expected: Weather details for \"San Juan\" and \"El Yunque\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Fetch weather for selected places \n",
    "response2 = agent.run(\"what is the wether in those places?\")\n",
    "\n",
    "print(response2) # Expected: Weather details for \"San Juan\" and \"El Yunque\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Load API Keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')\n",
    "\n",
    "# Municipality Mapping\n",
    "municipality_mapping = {\n",
    "    'Adjuntas': 'Adjuntas, PR', 'Aguada': 'Aguada, PR', 'Aguadilla': 'Aguadilla, PR', 'Aguas Buenas': 'Aguas Buenas, PR', 'Aibonito': 'Aibonito, PR',\n",
    "     'Arecibo': 'Arecibo, PR', 'Arroyo': 'Arroyo, PR', 'A√±asco': 'A√±asco, PR', 'Barceloneta': 'Barceloneta, PR', 'Barranquitas': 'Barranquitas, PR',\n",
    "     'Bayam√≥n': 'Bayam√≥n, PR', 'Cabo Rojo': 'Cabo Rojo, PR', 'Caguas': 'Caguas, PR', 'Camuy': 'Camuy, PR', 'Can√≥vanas': 'Can√≥vanas, PR',\n",
    "     'Carolina': 'Carolina, PR', 'Cata√±o': 'Cata√±o, PR', 'Cayey': 'Cayey, PR', 'Ceiba': 'Ceiba, PR', 'Ciales': 'Ciales, PR', 'Cidra': 'Cidra, PR',\n",
    "     'Coamo': 'Coamo, PR', 'Comer√≠o': 'Comer√≠o, PR', 'Corozal': 'Corozal, PR', 'Culebra': 'Culebra, PR', 'Dorado': 'Dorado, PR', 'Fajardo': 'Fajardo, PR',\n",
    "     'Florida': 'Florida, PR', 'Guayama': 'Guayama, PR', 'Guayanilla': 'Guayanilla, PR', 'Guaynabo': 'Guaynabo, PR', 'Gurabo': 'Gurabo, PR',\n",
    "     'Gu√°nica': 'Gu√°nica, PR', 'Hatillo': 'Hatillo, PR', 'Hormigueros': 'Hormigueros, PR', 'Humacao': 'Humacao, PR', 'Isabela': 'Isabela, PR',\n",
    "     'Jayuya': 'Jayuya, PR', 'Juana D√≠az': 'Juana D√≠az, PR', 'Juncos': 'Juncos, PR', 'Lajas': 'Lajas, PR', 'Lares': 'Lares, PR',\n",
    "     'Las Mar√≠as': 'Las Mar√≠as, PR', 'Las Piedras': 'Las Piedras, PR', 'Lo√≠za': 'Lo√≠za, PR', 'Luquillo': 'Luquillo, PR', 'Manat√≠': 'Manat√≠, PR',\n",
    "     'Maricao': 'Maricao, PR', 'Maunabo': 'Maunabo, PR', 'Mayag√ºez': 'Mayag√ºez, PR', 'Moca': 'Moca, PR', 'Morovis': 'Morovis, PR',\n",
    "     'Naguabo': 'Naguabo, PR', 'Naranjito': 'Naranjito, PR', 'Orocovis': 'Orocovis, PR', 'Patillas': 'Patillas, PR', 'Pe√±uelas': 'Pe√±uelas, PR',\n",
    "     'Ponce': 'Ponce, PR', 'Quebradillas': 'Quebradillas, PR', 'Rinc√≥n': 'Rinc√≥n, PR', 'R√≠o Grande': 'R√≠o Grande, PR',\n",
    "     'Sabana Grande': 'Sabana Grande, PR', 'Salinas': 'Salinas, PR', 'San Germ√°n': 'San Germ√°n, PR', 'San Juan': 'San Juan, PR',\n",
    "     'San Lorenzo': 'San Lorenzo, PR', 'San Sebasti√°n': 'San Sebasti√°n, PR', 'Santa Isabel': 'Santa Isabel, PR', 'Toa Alta': 'Toa Alta, PR',\n",
    "     'Toa Baja': 'Toa Baja, PR', 'Trujillo Alto': 'Trujillo Alto, PR', 'Utuado': 'Utuado, PR', 'Vega Alta': 'Vega Alta, PR', 'Vega Baja': 'Vega Baja, PR',\n",
    "     'Vieques': 'Vieques, PR', 'Villalba': 'Villalba, PR', 'Yabucoa': 'Yabucoa, PR', 'Yauco': 'Yauco, PR'\n",
    "}\n",
    "\n",
    "# ========== 1. Prompt Templates ==========\n",
    "condense_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Given the conversation history and the latest user query, rephrase the question to be standalone.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User Query:\n",
    "{question}\n",
    "\n",
    "### Rephrased Question:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "combine_docs_custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are an AI travel planner helping users design an itinerary.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User's Question:\n",
    "{question}\n",
    "\n",
    "### Retrieved Landmark Data:\n",
    "{context}\n",
    "\n",
    "### Instructions:\n",
    "- Provide a well-structured day-by-day itinerary.\n",
    "- Ensure continuity with previous discussions.\n",
    "- Prioritize locations based on user interest.\n",
    "- If multiple options exist, suggest the best ones.\n",
    "- Avoid repeating information already given.\n",
    "- At the end, ask the user how many days they are staying.\n",
    "\n",
    "### Final Itinerary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ========== 2. Initialize LLM and Memory ==========\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# ========== 3. ChromaDB Retrieval ==========\n",
    "vectorstore = Chroma(collection_name=\"landmarks_rag\", embedding_function=OpenAIEmbeddings(api_key=OPENAI_API_KEY))\n",
    "retriever = vectorstore.as_retriever(k=3)\n",
    "\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\",\n",
    "    condense_question_prompt=condense_prompt,\n",
    "    combine_docs_chain_kwargs=dict(prompt=combine_docs_custom_prompt)\n",
    ")\n",
    "\n",
    "qa_tool = Tool(\n",
    "    name=\"Puerto Rico Travel Guide\",\n",
    "    func=retrieval_chain.invoke,\n",
    "    description=\"Retrieve top locations to visit in Puerto Rico based on user preferences.\"\n",
    ")\n",
    "\n",
    "# ========== 4. Extract Locations ==========\n",
    "location_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=\"Extract only the names of locations from this text: {response}. Provide them as a comma-separated list.\"\n",
    ")\n",
    "\n",
    "location_extraction_chain = LLMChain(llm=llm, prompt=location_extraction_prompt)\n",
    "\n",
    "def extract_locations_from_response(response):\n",
    "    \"\"\"Extracts locations using LLM processing.\"\"\"\n",
    "    location_list = location_extraction_chain.invoke({\"response\": response})  # FIXED: Correct input format\n",
    "    extracted_places = [loc.strip() for loc in location_list.split(\",\") if loc.strip()]\n",
    "    valid_locations = [loc for loc in extracted_places if loc in municipality_mapping]\n",
    "    return valid_locations\n",
    "\n",
    "# ========== 5. Extract Number of Days from Memory ==========\n",
    "def get_trip_duration():\n",
    "    \"\"\"Infers the number of days from conversation memory.\"\"\"\n",
    "    messages = memory.chat_memory.messages\n",
    "    for message in reversed(messages):\n",
    "        if \"days\" in message.content.lower():\n",
    "            try:\n",
    "                words = message.content.split()\n",
    "                for i, word in enumerate(words):\n",
    "                    if word.isdigit():  # If a number is found\n",
    "                        return int(word)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None  # If not found\n",
    "\n",
    "# ========== 6. Itinerary Generator ==========\n",
    "import random\n",
    "\n",
    "def generate_itinerary(selected_places):\n",
    "    \"\"\"Generates a structured itinerary by distributing locations across inferred days.\"\"\"\n",
    "    num_days = get_trip_duration()\n",
    "    \n",
    "    if num_days is None:\n",
    "        num_days = int(input(\"\\nHow many days is your trip? \"))  # Ask only if missing\n",
    "        memory.chat_memory.add_user_message(f\"My trip is {num_days} days.\")  # Store in memory\n",
    "\n",
    "    itinerary = \"\"\n",
    "    places_per_day = max(1, len(selected_places) // num_days)\n",
    "    random.shuffle(selected_places)\n",
    "\n",
    "    for day in range(1, num_days + 1):\n",
    "        start_idx = (day - 1) * places_per_day\n",
    "        end_idx = start_idx + places_per_day\n",
    "        day_places = selected_places[start_idx:end_idx]\n",
    "\n",
    "        if not day_places:\n",
    "            break\n",
    "\n",
    "        itinerary += f\"\\nüìÖ **Day {day}:**\\n\"\n",
    "        for place in day_places:\n",
    "            itinerary += f\"- Visit **{place}** (Located in {municipality_mapping.get(place, 'Unknown Municipality')})\\n\"\n",
    "\n",
    "    return itinerary.strip()\n",
    "\n",
    "# ========== 7. Weather Retrieval ==========\n",
    "def get_weather(location):\n",
    "    \"\"\"Fetch real-time weather for a given municipality.\"\"\"\n",
    "    formatted_location = municipality_mapping.get(location, location)\n",
    "\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": formatted_location, \"appid\": OPENWEATHER_API_KEY, \"units\": \"metric\"}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        weather = data[\"weather\"][0][\"description\"]\n",
    "        temp = data[\"main\"][\"temp\"]\n",
    "        return f\"The weather in {formatted_location} is {weather} with a temperature of {temp}¬∞C.\"\n",
    "    else:\n",
    "        return f\"Could not fetch weather data for {formatted_location}.\"\n",
    "\n",
    "def get_weather_for_selected_places(selected_places):\n",
    "    \"\"\"Fetches weather for selected locations.\"\"\"\n",
    "    locations = [loc.strip() for loc in selected_places if loc.strip()]\n",
    "    if not locations:\n",
    "        return \"Please provide at least one valid location.\"\n",
    "    \n",
    "    weather_reports = [get_weather(location) for location in locations]\n",
    "    return \"\\n\".join(weather_reports)\n",
    "\n",
    "weather_tool = Tool(\n",
    "    name=\"Get Weather for Selected Places\",\n",
    "    func=get_weather_for_selected_places,\n",
    "    description=\"Retrieve weather for selected travel locations.\"\n",
    ")\n",
    "\n",
    "# ========== 8. AI Agent ==========\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool, weather_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# ========== 9. Simplified Chatbot Execution ==========\n",
    "def travel2pr_planner():\n",
    "    print(\"\\nüöÄ Welcome to the AI Travel Planner!\")\n",
    "    print(\"üí° Type 'exit' anytime to stop.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nUser: \")\n",
    "        if user_query.lower() == \"exit\":\n",
    "            print(\"\\nüëã Exiting AI Travel Planner. Safe travels!\")\n",
    "            break\n",
    "\n",
    "        response = agent.invoke(user_query)  # FIXED: Correct method for agent execution\n",
    "        print(\"\\nüìù AI Response:\\n\", response)\n",
    "\n",
    "        extracted_locations = extract_locations_from_response(response)\n",
    "\n",
    "        if not extracted_locations:\n",
    "            print(\"\\n‚ö†Ô∏è No valid locations found. Let's refine the search...\")\n",
    "            continue  # Ask again\n",
    "\n",
    "        itinerary = generate_itinerary(extracted_locations)\n",
    "        weather_info = get_weather_for_selected_places(extracted_locations)\n",
    "\n",
    "        print(\"\\nüìÖ **Your Itinerary:**\\n\", itinerary)\n",
    "        print(\"\\nüå§ **Weather Report:**\\n\", weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chatbot\n",
    "travel2pr_planner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel2pr_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
