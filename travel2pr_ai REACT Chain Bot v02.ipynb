{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment API Keys variables from .env file \n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt templates\n",
    "condense_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Given the conversation history and the latest user query, rephrase the question to be standalone, keeping it concise but maintaining all necessary details.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### Latest User Query:\n",
    "{question}\n",
    "\n",
    "### Standalone Question for Retrieval:\n",
    "\"\"\")\n",
    "\n",
    "combine_docs_custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are an AI travel planner helping users design an itinerary. Use the retrieved information about landmarks and the user's past preferences to generate a relevant and coherent travel recommendation.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User's Latest Question:\n",
    "{question}\n",
    "\n",
    "### Retrieved Landmark Information:\n",
    "{context}\n",
    "\n",
    "### Instructions:\n",
    "- Provide a well-structured travel recommendation based on the retrieved landmarks.\n",
    "- Ensure continuity with previous discussions.\n",
    "- Prioritize landmarks that match the user‚Äôs preferences.\n",
    "- If multiple options exist, suggest the best ones with reasoning.\n",
    "- Avoid repeating information already given in the conversation.\n",
    "- In the end ask the user which of these locations you will like to visit.\n",
    "\n",
    "### Final Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize LLM with ReAct Chain\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "\n",
    "# Define memory to store conversation history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "\n",
    "# Function to print chat history\n",
    "def print_chat_history():\n",
    "    print(\"\\nChat History:\")\n",
    "    for idx, msg in enumerate(memory.chat_memory.messages):\n",
    "        role = \"User\" if msg.type == \"human\" else \"AI\"\n",
    "        print(f\"{role}: {msg.content}\")\n",
    "\n",
    "# Connect to your existing ChromaDB collection\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"landmarks_rag\",\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "#Define the retriever and chain\n",
    "retriever = vectorstore.as_retriever(k=3)  # This fetches relevant landmarks\n",
    "\n",
    "# Set up the conversational retrieval chain\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,  # Using OpenAI's ChatGPT as the LLM\n",
    "    retriever=retriever,  # Connect to your ChromaDB retriever\n",
    "    memory=memory,\n",
    "    condense_question_prompt=condense_prompt,  # Ensures refined queries for retrieval\n",
    "    combine_docs_chain_kwargs=dict(prompt=combine_docs_custom_prompt)  # Customizes how retrieved docs are used\n",
    ")\n",
    "\n",
    "# Wrap QA Chain as a Tool \n",
    "qa_tool = Tool( name=\"Puerto Rico Travel Guide\",\n",
    "               func=retrieval_chain.run,\n",
    "               description=\"Retrieve the best places to visit in Puerto Rico based on user queries.\" \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================# 2. Extracting Locations from QA Response# ======================= \n",
    "location_extraction_prompt = PromptTemplate( input_variables=[\"response\"], \n",
    "                                            template=\"\"\" Extract only the location names from the following text: \"{response}\" Provide the locations as a comma-separated list. \"\"\" \n",
    "                                            ) \n",
    "                                            \n",
    "location_extraction_chain = LLMChain( llm=llm,\n",
    "                                     prompt=location_extraction_prompt )\n",
    "\n",
    "def extract_locations_from_response(response):\n",
    "    \"\"\"Extracts locations using the LLM chain.\"\"\"\n",
    "    location_list = location_extraction_chain.run(response)\n",
    "    return [loc.strip() for loc in location_list.split(\",\") if loc.strip()] \n",
    "\n",
    "# =======================# 3. Asking the User for Their Selected Places# =======================\n",
    "def ask_user_for_places(query): \n",
    "    \"\"\"Asks the user to select places they are interested in visiting.\"\"\"\n",
    "    # Retrieve recommended locations from QA #\n",
    "    recommended_places = qa_tool.run(query) \n",
    "    extracted_locations = extract_locations_from_response(recommended_places)\n",
    "    if extracted_locations:\n",
    "        weather_details = get_weather_for_selected_places(extracted_locations)\n",
    "        res = f\"Here are some great places to visit: {', '.join(extracted_locations)}. {weather_details}. Which ones do you want to visit?\"\n",
    "        return res\n",
    "    else:\n",
    "        return \"I couldn't find relevant locations. Please try another query.\"\n",
    "    # Wrap as a Tool\n",
    "\n",
    "ask_places_tool = Tool( name=\"Ask User for Selected Places\", func=ask_user_for_places, description=\"Ask the user which places they want to visit from the recommended list.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================# 4. Getting Weather for Selected Locations# =======================# \n",
    "def get_weather(location):\n",
    "    \"\"\"Fetch real-time weather for a given location.\"\"\"\n",
    "    api_key = OPENWEATHER_API_KEY  # Replace with your API key\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": location, \"appid\": api_key, \"units\": \"metric\"}\n",
    "    response = requests.get(base_url, params=params) \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        weather = data[\"weather\"][0][\"description\"]\n",
    "        temp = data[\"main\"][\"temp\"]\n",
    "        return f\"The weather in {location} is {weather} with a temperature of {temp}¬∞C.\"\n",
    "    \n",
    "    else: return f\"Could not fetch weather data for {location}.\"\n",
    "    \n",
    "def get_weather_for_selected_places(selected_places):\n",
    "    \"\"\"Fetches weather for the user-selected locations.\"\"\"\n",
    "    locations = [loc.strip() for loc in selected_places.split(\",\") if loc.strip()]\n",
    "    if not locations:\n",
    "        return \"Please provide at least one valid location.\"\n",
    "    weather_reports = [get_weather(location) for location in locations]\n",
    "    return \"\\n\".join(weather_reports) \n",
    "\n",
    "# Wrap Weather Fetching as a Tool\n",
    "weather_tool = Tool( name=\"Get Weather for Selected Places\", func=get_weather_for_selected_places, description=\"Retrieve weather for the places selected by the user.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent( tools=[qa_tool, ask_places_tool, weather_tool],\n",
    "                          # Adding all tools \n",
    "                          llm=llm,\n",
    "                          agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, # Keeps conversation context\n",
    "                          verbose=True,\n",
    "                          memory=memory \n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get recommended places\n",
    "response1 = agent.run(\"What are the best places to visit in Puerto Rico?\")\n",
    "\n",
    "print(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected: \"Here are some great places: San Juan, El Yunque, Culebra... Which ones do you want to visit?\"# Simulate User Input \n",
    "user_selected_places = \"San Juan and Ponce\"\n",
    "\n",
    "# Step 2: Fetch weather for selected places \n",
    "response2 = agent.run(f\"I want to visit {user_selected_places}\")\n",
    "\n",
    "print(response2) # Expected: Weather details for \"San Juan\" and \"El Yunque\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Fetch weather for selected places \n",
    "response2 = agent.run(\"what is the wether in those places?\")\n",
    "\n",
    "print(response2) # Expected: Weather details for \"San Juan\" and \"El Yunque\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Load API Keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')\n",
    "\n",
    "# Municipality Mapping\n",
    "municipality_mapping = {\n",
    "    'Adjuntas': 'Adjuntas, PR', 'Aguada': 'Aguada, PR', 'Aguadilla': 'Aguadilla, PR', 'Aguas Buenas': 'Aguas Buenas, PR', 'Aibonito': 'Aibonito, PR',\n",
    "     'Arecibo': 'Arecibo, PR', 'Arroyo': 'Arroyo, PR', 'A√±asco': 'A√±asco, PR', 'Barceloneta': 'Barceloneta, PR', 'Barranquitas': 'Barranquitas, PR',\n",
    "     'Bayam√≥n': 'Bayam√≥n, PR', 'Cabo Rojo': 'Cabo Rojo, PR', 'Caguas': 'Caguas, PR', 'Camuy': 'Camuy, PR', 'Can√≥vanas': 'Can√≥vanas, PR',\n",
    "     'Carolina': 'Carolina, PR', 'Cata√±o': 'Cata√±o, PR', 'Cayey': 'Cayey, PR', 'Ceiba': 'Ceiba, PR', 'Ciales': 'Ciales, PR', 'Cidra': 'Cidra, PR',\n",
    "     'Coamo': 'Coamo, PR', 'Comer√≠o': 'Comer√≠o, PR', 'Corozal': 'Corozal, PR', 'Culebra': 'Culebra, PR', 'Dorado': 'Dorado, PR', 'Fajardo': 'Fajardo, PR',\n",
    "     'Florida': 'Florida, PR', 'Guayama': 'Guayama, PR', 'Guayanilla': 'Guayanilla, PR', 'Guaynabo': 'Guaynabo, PR', 'Gurabo': 'Gurabo, PR',\n",
    "     'Gu√°nica': 'Gu√°nica, PR', 'Hatillo': 'Hatillo, PR', 'Hormigueros': 'Hormigueros, PR', 'Humacao': 'Humacao, PR', 'Isabela': 'Isabela, PR',\n",
    "     'Jayuya': 'Jayuya, PR', 'Juana D√≠az': 'Juana D√≠az, PR', 'Juncos': 'Juncos, PR', 'Lajas': 'Lajas, PR', 'Lares': 'Lares, PR',\n",
    "     'Las Mar√≠as': 'Las Mar√≠as, PR', 'Las Piedras': 'Las Piedras, PR', 'Lo√≠za': 'Lo√≠za, PR', 'Luquillo': 'Luquillo, PR', 'Manat√≠': 'Manat√≠, PR',\n",
    "     'Maricao': 'Maricao, PR', 'Maunabo': 'Maunabo, PR', 'Mayag√ºez': 'Mayag√ºez, PR', 'Moca': 'Moca, PR', 'Morovis': 'Morovis, PR',\n",
    "     'Naguabo': 'Naguabo, PR', 'Naranjito': 'Naranjito, PR', 'Orocovis': 'Orocovis, PR', 'Patillas': 'Patillas, PR', 'Pe√±uelas': 'Pe√±uelas, PR',\n",
    "     'Ponce': 'Ponce, PR', 'Quebradillas': 'Quebradillas, PR', 'Rinc√≥n': 'Rinc√≥n, PR', 'R√≠o Grande': 'R√≠o Grande, PR',\n",
    "     'Sabana Grande': 'Sabana Grande, PR', 'Salinas': 'Salinas, PR', 'San Germ√°n': 'San Germ√°n, PR', 'San Juan': 'San Juan, PR',\n",
    "     'San Lorenzo': 'San Lorenzo, PR', 'San Sebasti√°n': 'San Sebasti√°n, PR', 'Santa Isabel': 'Santa Isabel, PR', 'Toa Alta': 'Toa Alta, PR',\n",
    "     'Toa Baja': 'Toa Baja, PR', 'Trujillo Alto': 'Trujillo Alto, PR', 'Utuado': 'Utuado, PR', 'Vega Alta': 'Vega Alta, PR', 'Vega Baja': 'Vega Baja, PR',\n",
    "     'Vieques': 'Vieques, PR', 'Villalba': 'Villalba, PR', 'Yabucoa': 'Yabucoa, PR', 'Yauco': 'Yauco, PR'\n",
    "}\n",
    "\n",
    "# ========== 1. Prompt Templates ==========\n",
    "condense_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Given the conversation history and the latest user query, rephrase the question to be standalone.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User Query:\n",
    "{question}\n",
    "\n",
    "### Rephrased Question:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "combine_docs_custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are an AI travel planner helping users design an itinerary.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User's Question:\n",
    "{question}\n",
    "\n",
    "### Retrieved Landmark Data:\n",
    "{context}\n",
    "\n",
    "### Instructions:\n",
    "- Provide a well-structured day-by-day itinerary.\n",
    "- Ensure continuity with previous discussions.\n",
    "- Prioritize locations based on user interest.\n",
    "- If multiple options exist, suggest the best ones.\n",
    "- Avoid repeating information already given.\n",
    "- At the end, ask the user how many days they are staying.\n",
    "\n",
    "### Final Itinerary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ========== 2. Initialize LLM and Memory ==========\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# ========== 3. ChromaDB Retrieval ==========\n",
    "vectorstore = Chroma(collection_name=\"landmarks_rag\", embedding_function=OpenAIEmbeddings(api_key=OPENAI_API_KEY))\n",
    "retriever = vectorstore.as_retriever(k=3)\n",
    "\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\",\n",
    "    condense_question_prompt=condense_prompt,\n",
    "    combine_docs_chain_kwargs=dict(prompt=combine_docs_custom_prompt)\n",
    ")\n",
    "\n",
    "qa_tool = Tool(\n",
    "    name=\"Puerto Rico Travel Guide\",\n",
    "    func=retrieval_chain.invoke,\n",
    "    description=\"Retrieve top locations to visit in Puerto Rico based on user preferences.\"\n",
    ")\n",
    "\n",
    "# ========== 4. Extract Locations ==========\n",
    "location_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=\"Extract only the names of locations from this text: {response}. Provide them as a comma-separated list.\"\n",
    ")\n",
    "\n",
    "location_extraction_chain = LLMChain(llm=llm, prompt=location_extraction_prompt)\n",
    "\n",
    "def extract_locations_from_response(response):\n",
    "    \"\"\"Extracts locations using LLM processing.\"\"\"\n",
    "    location_list = location_extraction_chain.invoke({\"response\": response})  # FIXED: Correct input format\n",
    "    extracted_places = [loc.strip() for loc in location_list.split(\",\") if loc.strip()]\n",
    "    valid_locations = [loc for loc in extracted_places if loc in municipality_mapping]\n",
    "    return valid_locations\n",
    "\n",
    "# ========== 5. Extract Number of Days from Memory ==========\n",
    "def get_trip_duration():\n",
    "    \"\"\"Infers the number of days from conversation memory.\"\"\"\n",
    "    messages = memory.chat_memory.messages\n",
    "    for message in reversed(messages):\n",
    "        if \"days\" in message.content.lower():\n",
    "            try:\n",
    "                words = message.content.split()\n",
    "                for i, word in enumerate(words):\n",
    "                    if word.isdigit():  # If a number is found\n",
    "                        return int(word)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None  # If not found\n",
    "\n",
    "# ========== 6. Itinerary Generator ==========\n",
    "import random\n",
    "\n",
    "def generate_itinerary(selected_places):\n",
    "    \"\"\"Generates a structured itinerary by distributing locations across inferred days.\"\"\"\n",
    "    num_days = get_trip_duration()\n",
    "    \n",
    "    if num_days is None:\n",
    "        num_days = int(input(\"\\nHow many days is your trip? \"))  # Ask only if missing\n",
    "        memory.chat_memory.add_user_message(f\"My trip is {num_days} days.\")  # Store in memory\n",
    "\n",
    "    itinerary = \"\"\n",
    "    places_per_day = max(1, len(selected_places) // num_days)\n",
    "    random.shuffle(selected_places)\n",
    "\n",
    "    for day in range(1, num_days + 1):\n",
    "        start_idx = (day - 1) * places_per_day\n",
    "        end_idx = start_idx + places_per_day\n",
    "        day_places = selected_places[start_idx:end_idx]\n",
    "\n",
    "        if not day_places:\n",
    "            break\n",
    "\n",
    "        itinerary += f\"\\nüìÖ **Day {day}:**\\n\"\n",
    "        for place in day_places:\n",
    "            itinerary += f\"- Visit **{place}** (Located in {municipality_mapping.get(place, 'Unknown Municipality')})\\n\"\n",
    "\n",
    "    return itinerary.strip()\n",
    "\n",
    "# ========== 7. Weather Retrieval ==========\n",
    "def get_weather(location):\n",
    "    \"\"\"Fetch real-time weather for a given municipality.\"\"\"\n",
    "    formatted_location = municipality_mapping.get(location, location)\n",
    "\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": formatted_location, \"appid\": OPENWEATHER_API_KEY, \"units\": \"metric\"}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        weather = data[\"weather\"][0][\"description\"]\n",
    "        temp = data[\"main\"][\"temp\"]\n",
    "        return f\"The weather in {formatted_location} is {weather} with a temperature of {temp}¬∞C.\"\n",
    "    else:\n",
    "        return f\"Could not fetch weather data for {formatted_location}.\"\n",
    "\n",
    "def get_weather_for_selected_places(selected_places):\n",
    "    \"\"\"Fetches weather for selected locations.\"\"\"\n",
    "    locations = [loc.strip() for loc in selected_places if loc.strip()]\n",
    "    if not locations:\n",
    "        return \"Please provide at least one valid location.\"\n",
    "    \n",
    "    weather_reports = [get_weather(location) for location in locations]\n",
    "    return \"\\n\".join(weather_reports)\n",
    "\n",
    "weather_tool = Tool(\n",
    "    name=\"Get Weather for Selected Places\",\n",
    "    func=get_weather_for_selected_places,\n",
    "    description=\"Retrieve weather for selected travel locations.\"\n",
    ")\n",
    "\n",
    "# ========== 8. AI Agent ==========\n",
    "agent = initialize_agent(\n",
    "    tools=[qa_tool, weather_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# ========== 9. Simplified Chatbot Execution ==========\n",
    "def travel2pr_planner():\n",
    "    print(\"\\nüöÄ Welcome to the AI Travel Planner!\")\n",
    "    print(\"üí° Type 'exit' anytime to stop.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nUser: \")\n",
    "        if user_query.lower() == \"exit\":\n",
    "            print(\"\\nüëã Exiting AI Travel Planner. Safe travels!\")\n",
    "            break\n",
    "\n",
    "        response = agent.invoke(user_query)  # FIXED: Correct method for agent execution\n",
    "        print(\"\\nüìù AI Response:\\n\", response)\n",
    "\n",
    "        extracted_locations = extract_locations_from_response(response)\n",
    "\n",
    "        if not extracted_locations:\n",
    "            print(\"\\n‚ö†Ô∏è No valid locations found. Let's refine the search...\")\n",
    "            continue  # Ask again\n",
    "\n",
    "        itinerary = generate_itinerary(extracted_locations)\n",
    "        weather_info = get_weather_for_selected_places(extracted_locations)\n",
    "\n",
    "        print(\"\\nüìÖ **Your Itinerary:**\\n\", itinerary)\n",
    "        print(\"\\nüå§ **Weather Report:**\\n\", weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chatbot\n",
    "travel2pr_planner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå BLOCK 1: Import Required Libraries\n",
    "import os\n",
    "import requests\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain, RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Load API Keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')\n",
    "\n",
    "# üìå BLOCK 2: Initialize LLM & Memory\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# üìå BLOCK 3: Connect to ChromaDB Vectorstore & Vectorstore (RAG) Retrieval\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"landmarks_rag\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=OPENAI_API_KEY)\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=3)  # Retrieve top 3 relevant documents\n",
    "\n",
    "# üìå BLOCK 4: Prompt Templates\n",
    "travel_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are an AI travel planner for Puerto Rico.\n",
    "Based on user queries and conversation history, provide a structured day-by-day recommended itinerary.\n",
    "\n",
    "### Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "### User Query:\n",
    "{question}\n",
    "\n",
    "### Recommended Locations:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# üìå BLOCK 5: Conversational Retrieval Chain\n",
    "travel_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\",\n",
    "    condense_question_prompt=travel_prompt\n",
    ")\n",
    "\n",
    "# üìå BLOCK 6: Weather Retrieval (SINGLE INPUT)\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Fetches real-time weather data for a city.\"\"\"\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": city, \"appid\": OPENWEATHER_API_KEY, \"units\": \"metric\"}\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "        if response.status_code == 200:\n",
    "            weather_description = data[\"weather\"][0][\"description\"]\n",
    "            temperature = data[\"main\"][\"temp\"]\n",
    "            return f\"{city}: {weather_description}, {temperature}¬∞C\"\n",
    "        return f\"Error fetching weather for {city}: {data.get('message', 'Unknown error')}\"\n",
    "    except Exception as e:\n",
    "        return f\"API request failed: {str(e)}\"\n",
    "\n",
    "weather_tool = tool(get_weather)\n",
    "\n",
    "# üìå BLOCK 7: Generate Itinerary\n",
    "\n",
    "def generate_itinerary(locations):\n",
    "    \"\"\"Creates a structured itinerary from selected locations.\"\"\"\n",
    "    itinerary = \"\"\"\n",
    "üìÜ **Your Travel Itinerary** üìÜ\n",
    "\"\"\"\n",
    "    for i, location in enumerate(locations, 1):\n",
    "        itinerary += f\"\\nüìÖ Day {i}: Visit **{location}**\"\n",
    "    return itinerary\n",
    "\n",
    "# üìå BLOCK 8: Initialize LangChain REACT Agent\n",
    "agent = initialize_agent(\n",
    "    tools=[weather_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# üìå BLOCK 9: Conversational Chatbot\n",
    "def travel2pr_chatbot():\n",
    "    \"\"\"Runs the chatbot conversation flow.\"\"\"\n",
    "    print(\"üó∫Ô∏è Welcome to Puerto Rico AI Travel Planner! üó∫Ô∏è\\n\")\n",
    "    while True:\n",
    "        question = input(\"User: \")\n",
    "        if question.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Goodbye! Safe travels!\")\n",
    "            break\n",
    "        travel_response = travel_chain.run(question)\n",
    "        print(\"\\nüìå Recommended Locations:\\n\", travel_response)\n",
    "        selected_locations = input(\"\\n‚úàÔ∏è Which locations do you want to visit? (Separate by commas): \").split(\",\")\n",
    "        weather_info = [get_weather(loc.strip()) for loc in selected_locations]\n",
    "        print(\"\\nüå§ Weather Updates:\", \"\\n\".join(weather_info))\n",
    "        itinerary = generate_itinerary(selected_locations)\n",
    "        print(itinerary)\n",
    "        confirmation = input(\"\\n‚úÖ Does this itinerary work for you? (yes/no): \")\n",
    "        if confirmation.lower() == \"yes\":\n",
    "            print(\"\\nüéâ Your itinerary is confirmed! Have a great trip!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nüîÑ Let's adjust your itinerary further!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    travel2pr_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain, RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# üìå BLOCK 1: Load Environment Variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')\n",
    "\n",
    "# üìå BLOCK 2: Initialize LLM\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "\n",
    "# üìå BLOCK 3: Initialize Memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# üìå BLOCK 4: Connect to Vectorstore (Chroma)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"landmarks_rag\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=OPENAI_API_KEY)\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=5)  # Get top 5 landmarks\n",
    "\n",
    "# üìå BLOCK 5: Prompt Templates for Structured Travel Planning\n",
    "travel_prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful AI travel planner for Puerto Rico.\n",
    "\n",
    "### Chat History:\n",
    "{chat_history}\n",
    "\n",
    "### User Question:\n",
    "{question}\n",
    "\n",
    "### Instructions:\n",
    "- Provide well-structured travel recommendations.\n",
    "- Ask clarifying questions if needed.\n",
    "- Ensure recommendations are relevant to the user's interests and trip duration.\n",
    "- If the user has not provided travel dates or number of days, ask for them.\n",
    "\n",
    "### AI Response:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "travel_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=travel_prompt\n",
    ")\n",
    "\n",
    "# üìå BLOCK 6: Municipality Mapping for Weather API\n",
    "municipality_mapping = {\n",
    "    'Adjuntas': 'Adjuntas, PR', 'Aguada': 'Aguada, PR', 'Aguadilla': 'Aguadilla, PR', 'Aguas Buenas': 'Aguas Buenas, PR', 'Aibonito': 'Aibonito, PR',\n",
    "     'Arecibo': 'Arecibo, PR', 'Arroyo': 'Arroyo, PR', 'A√±asco': 'A√±asco, PR', 'Barceloneta': 'Barceloneta, PR', 'Barranquitas': 'Barranquitas, PR',\n",
    "     'Bayam√≥n': 'Bayam√≥n, PR', 'Cabo Rojo': 'Cabo Rojo, PR', 'Caguas': 'Caguas, PR', 'Camuy': 'Camuy, PR', 'Can√≥vanas': 'Can√≥vanas, PR',\n",
    "     'Carolina': 'Carolina, PR', 'Cata√±o': 'Cata√±o, PR', 'Cayey': 'Cayey, PR', 'Ceiba': 'Ceiba, PR', 'Ciales': 'Ciales, PR', 'Cidra': 'Cidra, PR',\n",
    "     'Coamo': 'Coamo, PR', 'Comer√≠o': 'Comer√≠o, PR', 'Corozal': 'Corozal, PR', 'Culebra': 'Culebra, PR', 'Dorado': 'Dorado, PR', 'Fajardo': 'Fajardo, PR',\n",
    "     'Florida': 'Florida, PR', 'Guayama': 'Guayama, PR', 'Guayanilla': 'Guayanilla, PR', 'Guaynabo': 'Guaynabo, PR', 'Gurabo': 'Gurabo, PR',\n",
    "     'Gu√°nica': 'Gu√°nica, PR', 'Hatillo': 'Hatillo, PR', 'Hormigueros': 'Hormigueros, PR', 'Humacao': 'Humacao, PR', 'Isabela': 'Isabela, PR',\n",
    "     'Jayuya': 'Jayuya, PR', 'Juana D√≠az': 'Juana D√≠az, PR', 'Juncos': 'Juncos, PR', 'Lajas': 'Lajas, PR', 'Lares': 'Lares, PR',\n",
    "     'Las Mar√≠as': 'Las Mar√≠as, PR', 'Las Piedras': 'Las Piedras, PR', 'Lo√≠za': 'Lo√≠za, PR', 'Luquillo': 'Luquillo, PR', 'Manat√≠': 'Manat√≠, PR',\n",
    "     'Maricao': 'Maricao, PR', 'Maunabo': 'Maunabo, PR', 'Mayag√ºez': 'Mayag√ºez, PR', 'Moca': 'Moca, PR', 'Morovis': 'Morovis, PR',\n",
    "     'Naguabo': 'Naguabo, PR', 'Naranjito': 'Naranjito, PR', 'Orocovis': 'Orocovis, PR', 'Patillas': 'Patillas, PR', 'Pe√±uelas': 'Pe√±uelas, PR',\n",
    "     'Ponce': 'Ponce, PR', 'Quebradillas': 'Quebradillas, PR', 'Rinc√≥n': 'Rinc√≥n, PR', 'R√≠o Grande': 'R√≠o Grande, PR',\n",
    "     'Sabana Grande': 'Sabana Grande, PR', 'Salinas': 'Salinas, PR', 'San Germ√°n': 'San Germ√°n, PR', 'San Juan': 'San Juan, PR',\n",
    "     'San Lorenzo': 'San Lorenzo, PR', 'San Sebasti√°n': 'San Sebasti√°n, PR', 'Santa Isabel': 'Santa Isabel, PR', 'Toa Alta': 'Toa Alta, PR',\n",
    "     'Toa Baja': 'Toa Baja, PR', 'Trujillo Alto': 'Trujillo Alto, PR', 'Utuado': 'Utuado, PR', 'Vega Alta': 'Vega Alta, PR', 'Vega Baja': 'Vega Baja, PR',\n",
    "     'Vieques': 'Vieques, PR', 'Villalba': 'Villalba, PR', 'Yabucoa': 'Yabucoa, PR', 'Yauco': 'Yauco, PR'\n",
    "}\n",
    "\n",
    "# üìå BLOCK 7: Function to Get Weather\n",
    "def get_weather(location):\n",
    "    \"\"\"Fetches real-time weather data for valid municipalities.\"\"\"\n",
    "    formatted_location = municipality_mapping.get(location, location)\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\"q\": formatted_location, \"appid\": OPENWEATHER_API_KEY, \"units\": \"metric\"}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return f\"üå§Ô∏è Weather in {formatted_location}: {data['weather'][0]['description']}, {data['main']['temp']}¬∞C\"\n",
    "    else:\n",
    "        return f\"‚ö†Ô∏è Could not fetch weather for {formatted_location}.\"\n",
    "\n",
    "weather_tool = Tool(name=\"Weather\", func=get_weather, description=\"Retrieve weather for selected locations.\")\n",
    "\n",
    "# üìå BLOCK 8: Function to Extract Locations from AI Response\n",
    "location_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=\"Extract only valid locations from this text: {response}. Return them as a comma-separated list.\"\n",
    ")\n",
    "location_extraction_chain = LLMChain(llm=llm, prompt=location_extraction_prompt)\n",
    "\n",
    "def extract_locations(response):\n",
    "    \"\"\"Extracts valid locations from AI response.\"\"\"\n",
    "    location_data = location_extraction_chain.invoke({\"response\": response})  # Ensure correct invocation\n",
    "    \n",
    "    if isinstance(location_data, dict):\n",
    "        location_list = location_data.get(\"text\", \"\")  # Extracts actual text result if it's a dictionary\n",
    "    else:\n",
    "        location_list = str(location_data)  # Ensures it's a string\n",
    "\n",
    "    if not isinstance(location_list, str):\n",
    "        print(\"Warning: Unexpected location extraction output type:\", type(location_list))\n",
    "        return []\n",
    "\n",
    "    extracted_places = [loc.strip() for loc in location_list.split(\",\") if loc.strip()]\n",
    "    valid_locations = [loc for loc in extracted_places if loc in municipality_mapping]\n",
    "\n",
    "    return valid_locations\n",
    "\n",
    "# üìå BLOCK 9: Itinerary Generation\n",
    "def generate_itinerary(selected_places, num_days):\n",
    "    \"\"\"Generates a structured itinerary by distributing locations across days.\"\"\"\n",
    "    itinerary = \"\"\n",
    "    places_per_day = max(1, len(selected_places) // num_days)\n",
    "\n",
    "    for day in range(1, num_days + 1):\n",
    "        day_places = selected_places[(day - 1) * places_per_day : day * places_per_day]\n",
    "        itinerary += f\"\\nüìÖ **Day {day}:**\\n\"\n",
    "        for place in day_places:\n",
    "            itinerary += f\"- Visit **{place}** (Located in {municipality_mapping.get(place, 'Unknown Municipality')})\\n\"\n",
    "\n",
    "    return itinerary.strip()\n",
    "\n",
    "# üìå BLOCK 10: AI Chatbot\n",
    "def travel2pr_chatbot():\n",
    "    \"\"\"Handles user interactions and builds an itinerary.\"\"\"\n",
    "    print(\"\\nüó∫Ô∏è Welcome to Puerto Rico AI Travel Planner! üó∫Ô∏è\\n\")\n",
    "\n",
    "    # Collecting user details\n",
    "    travel_dates = input(\"üìÖ When are you planning to visit Puerto Rico? \")\n",
    "    num_days = int(input(\"üìÜ How many days will you stay? \"))\n",
    "\n",
    "    print(\"\\nüîé Generating travel recommendations...\\n\")\n",
    "    user_question = input(\"\\nUser: \")  # Get user query\n",
    "    travel_response = travel_chain.run(user_question)\n",
    "\n",
    "    print(\"\\nüìå Recommended Locations:\\n\", travel_response)\n",
    "\n",
    "    extracted_locations = extract_locations(travel_response)\n",
    "    weather_info = get_weather(extracted_locations[0]) if extracted_locations else \"No weather data available.\"\n",
    "\n",
    "    itinerary = generate_itinerary(extracted_locations, num_days)\n",
    "    \n",
    "    print(\"\\nüå§ Fetching weather for selected locations...\\n\", weather_info)\n",
    "    print(\"\\nüìÜ Generating your structured itinerary...\\n\", itinerary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    travel2pr_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chatbot v2.0: This configuration below works very fine to retreive and answer accurately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 1. Import Required Libraries\n",
    "import os\n",
    "import requests\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain, RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 2. Load API keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# üìå 3. Initialize Embedding Model & Initialize LLM\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "# üìå 4. Load Vectorstore (ChromaDB Collection)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"landmarks_rag\",\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# üìå 5. Define a Custom Prompt Template\n",
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],  # Ensure both variables are included\n",
    "    template=\"\"\"\n",
    "You are a Puerto Rico travel assistant. \n",
    "Use the retrieved information to provide the best travel recommendations.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# üìå 6. Set up the RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
    ")\n",
    "\n",
    "# üìå 7. Chatbot Function\n",
    "def travel2pr_chatbot():\n",
    "    print(\"\\nüó∫Ô∏è Welcome to the Puerto Rico AI Travel Planner! üó∫Ô∏è\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nUser: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"\\nüëã Goodbye! Have a great trip!\\n\")\n",
    "            break\n",
    "\n",
    "        print(\"\\nüîé Searching for travel recommendations...\\n\")\n",
    "        response = qa_chain.run(user_query)\n",
    "\n",
    "        print(\"\\nüìå Recommended Locations:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 8. Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    travel2pr_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chatbot v2.1: Converssational Flow Improvement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå BLOCK 1: Import Required Libraries\n",
    "import os\n",
    "import requests\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain, RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 2. Load API keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# üìå 3. Initialize Embedding Model & LLM\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=OPENAI_API_KEY)\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "\n",
    "# üìå 4. Load Vectorstore (ChromaDB Collection)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"landmarks_rag\",\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# üìå 5. Define a Custom Prompt Template with Follow-up\n",
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],  \n",
    "    template=\"\"\"\n",
    "You are a Puerto Rico travel assistant. \n",
    "Use the retrieved information to provide the best travel recommendations in a natural and engaging way.\n",
    "\n",
    "### Context (Relevant Information from RAG):\n",
    "{context}\n",
    "\n",
    "### User Question:\n",
    "{question}\n",
    "\n",
    "### AI Response:\n",
    "Based on the information available, here‚Äôs what I recommend:\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# üìå 6. Set up the RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
    ")\n",
    "\n",
    "# üìå 7. Conversational Chatbot Function (Improved Flow)\n",
    "def travel2pr_chatbot():\n",
    "    print(\"\\nüó∫Ô∏è Welcome to the Puerto Rico AI Travel Planner! üó∫Ô∏è\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nUser: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"\\nüëã Goodbye! Have a great trip!\\n\")\n",
    "            break\n",
    "\n",
    "        print(\"\\nüîé Searching for travel recommendations...\\n\")\n",
    "        response = qa_chain.run(user_query)\n",
    "\n",
    "        print(\"\\nüìå Recommended Locations:\\n\", response)\n",
    "\n",
    "        # Follow-up to keep the conversation going\n",
    "        follow_up = input(\"\\nWould you like more details or recommendations? (yes/no): \").strip().lower()\n",
    "        if follow_up in [\"no\", \"n\"]:\n",
    "            print(\"\\n‚úÖ Itinerary finalized! Enjoy your trip to Puerto Rico! üå¥‚úàÔ∏è\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå BLOCK 8: Run Chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    travel2pr_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chatbot v2.2: Better user preference tracking, Fluid conversation flow, Memory integration & Structured itinerary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå BLOCK 1: Import Required Libraries\n",
    "import os\n",
    "import requests\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain, RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# üìå Initialize Embedding Model & LLM\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=OPENAI_API_KEY)\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4-turbo\")\n",
    "\n",
    "# üìå Load Vectorstore (ChromaDB Collection)\n",
    "vectorstore = Chroma(collection_name=\"landmarks_rag\", embedding_function=embedding_model)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# üìå Define Custom Prompt Template\n",
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a Puerto Rico travel assistant. \n",
    "Use the retrieved information to provide the best travel recommendations and a structured travel itinerary.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### User Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# üìå Set up the RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
    ")\n",
    "\n",
    "# Tool to manage the itinerary\n",
    "class ItineraryManager:\n",
    "    def __init__(self):\n",
    "        self.itinerary = []\n",
    "\n",
    "    def add_to_itinerary(self, place):\n",
    "        self.itinerary.append(place)\n",
    "        return f\"‚úÖ {place} added to your itinerary!\"\n",
    "\n",
    "    def get_itinerary(self):\n",
    "        return \"\\n\".join([f\"- {place}\" for place in self.itinerary]) if self.itinerary else \"No places added yet.\"\n",
    "\n",
    "itinerary_tool = ItineraryManager()\n",
    "\n",
    "# üìå Memory for Tracking Selections\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "selected_places = []\n",
    "\n",
    "# üìå Conversational Chatbot Function\n",
    "def travel2pr_chatbot():\n",
    "    print(\"\\nüó∫Ô∏è Welcome to the Puerto Rico AI Travel Planner! üó∫Ô∏è\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"\\nUser: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"\\nüëã Goodbye! Have a great trip!\\n\")\n",
    "            break\n",
    "        \n",
    "        # Retrieve travel recommendations\n",
    "        print(\"\\nüîé Searching for travel recommendations...\\n\")\n",
    "        \n",
    "        # Load memory context\n",
    "        context_data = memory.load_memory_variables({})\n",
    "        context = context_data.get(\"chat_history\", \"No previous chat history.\")\n",
    "\n",
    "        # Ensure proper keys in invoke function\n",
    "        response = qa_chain.invoke({\"question\": user_query, \"context\": context})\n",
    "\n",
    "        # üîπ EXTRAER RESPUESTA COMO TEXTO\n",
    "        response_text = response[\"result\"] if isinstance(response, dict) and \"result\" in response else str(response)\n",
    "\n",
    "        # Check if the user is adding something to the itinerary\n",
    "        if \"add to itinerary\" in user_query.lower() or \"selected\" in response_text.lower():\n",
    "            itinerary_tool.add_to_itinerary(response_text)\n",
    "            print(\"\\n‚úÖ Added to your itinerary!\\n\")\n",
    "        elif \"show itinerary\" in user_query.lower():\n",
    "            print(\"\\nüìÜ Your Itinerary:\\n\", itinerary_tool.get_itinerary())\n",
    "        else:\n",
    "            print(\"\\nüìå Recommended Locations:\\n\", response_text)\n",
    "\n",
    "        # Ask if they want to finalize or continue\n",
    "        user_feedback = input(\"\\nWould you like to add this to your itinerary? (yes/no/finalize): \").strip().lower()\n",
    "\n",
    "        if user_feedback == \"yes\":\n",
    "            itinerary_tool.add_to_itinerary(response_text)\n",
    "            print(\"\\n‚úÖ Added to your itinerary!\")\n",
    "        elif user_feedback == \"finalize\":\n",
    "            print(\"\\nüìÜ Generating your structured itinerary...\\n\")\n",
    "            final_itinerary = f\"### Your 5-Day Puerto Rico Itinerary:\\n{itinerary_tool.get_itinerary()}\"\n",
    "            \n",
    "            print(\"\\n‚úÖ **Your itinerary is finalized!** Safe travels! üèùÔ∏è\")\n",
    "            print(\"\\nüìå Final Itinerary:\\n\", final_itinerary)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üó∫Ô∏è Welcome to the Puerto Rico AI Travel Planner! üó∫Ô∏è\n",
      "\n",
      "\n",
      "üîé Searching for travel recommendations...\n",
      "\n",
      "An error occurred: Missing some input keys: {'query'}\n"
     ]
    }
   ],
   "source": [
    "# üìå BLOCK 8: Run Chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        travel2pr_chatbot()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel2pr_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
